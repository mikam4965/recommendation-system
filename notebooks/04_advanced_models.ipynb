{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Advanced Models - Deep Learning & Explainability (V2.0)\n",
    "\n",
    "This notebook demonstrates the V2.0 models:\n",
    "1. **GRU4Rec** - Session-based recommendations with RNN\n",
    "2. **SASRec** - Self-Attentive Sequential Recommendation\n",
    "3. **Two-Tower** - Dual encoder with FAISS retrieval\n",
    "4. **Explainable AI** - Human-readable recommendation explanations\n",
    "\n",
    "## Scientific Contributions\n",
    "- **Novelty #2**: Session + History Fusion with attention-based combination\n",
    "- **Novelty #3**: Explainable e-commerce recommendations with funnel awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.loaders.retailrocket import RetailRocketLoader\n",
    "from src.data.processors.session_builder import SessionBuilder\n",
    "from src.data.processors.splitter import TimeBasedSplitter\n",
    "from src.data.features.user_features import UserFeatureExtractor\n",
    "from src.config import settings\n",
    "\n",
    "# Load data\n",
    "loader = RetailRocketLoader()\n",
    "events = loader.load_events()\n",
    "\n",
    "print(f\"Total events: {len(events):,}\")\n",
    "print(f\"Unique users: {events['visitor_id'].nunique():,}\")\n",
    "print(f\"Unique items: {events['item_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sessions\n",
    "session_builder = SessionBuilder(timeout_minutes=30)\n",
    "events = session_builder.build_sessions(events)\n",
    "\n",
    "# Filter short sessions for sequential models\n",
    "events_filtered = session_builder.filter_short_sessions(events, min_length=2)\n",
    "\n",
    "print(f\"\\nFiltered events: {len(events_filtered):,}\")\n",
    "print(f\"Sessions: {events_filtered['session_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "splitter = TimeBasedSplitter(\n",
    "    train_ratio=settings.train_ratio,\n",
    "    val_ratio=settings.val_ratio,\n",
    "    test_ratio=settings.test_ratio\n",
    ")\n",
    "train, val, test = splitter.split(events_filtered)\n",
    "\n",
    "print(f\"Train: {len(train):,}\")\n",
    "print(f\"Val: {len(val):,}\")\n",
    "print(f\"Test: {len(test):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract user features\n",
    "user_feature_extractor = UserFeatureExtractor()\n",
    "user_feature_extractor.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GRU4Rec - Session-based RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.sequential.gru4rec import GRU4RecRecommender\n",
    "from src.evaluation.evaluator import Evaluator\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = Evaluator(k_values=[5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GRU4Rec\n",
    "gru4rec = GRU4RecRecommender(\n",
    "    embedding_dim=64,\n",
    "    hidden_dim=128,\n",
    "    n_layers=1,\n",
    "    dropout=0.2,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=512,\n",
    "    epochs=5,  # Reduce for demo\n",
    "    loss_type='ce'\n",
    ")\n",
    "\n",
    "gru4rec.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate GRU4Rec\n",
    "gru4rec_results = evaluator.evaluate(\n",
    "    gru4rec, train, test,\n",
    "    n_items=20, max_users=2000\n",
    ")\n",
    "\n",
    "print(\"GRU4Rec Results:\")\n",
    "for k, v in gru4rec_results.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Session-based recommendation\n",
    "sample_session = train.groupby('session_id').apply(\n",
    "    lambda x: x['item_id'].tolist()\n",
    ").iloc[0][:5]\n",
    "\n",
    "print(f\"Sample session items: {sample_session}\")\n",
    "recs = gru4rec.recommend_by_item_ids(sample_session, n_items=5)\n",
    "print(f\"\\nRecommendations:\")\n",
    "for item_id, score in recs:\n",
    "    print(f\"  Item {item_id}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SASRec - Self-Attentive Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.sequential.sasrec import SASRecRecommender\n",
    "\n",
    "# Train SASRec\n",
    "sasrec = SASRecRecommender(\n",
    "    hidden_dim=64,\n",
    "    n_heads=2,\n",
    "    n_layers=2,\n",
    "    max_seq_length=50,\n",
    "    dropout=0.2,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=512,\n",
    "    epochs=5  # Reduce for demo\n",
    ")\n",
    "\n",
    "sasrec.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate SASRec\n",
    "sasrec_results = evaluator.evaluate(\n",
    "    sasrec, train, test,\n",
    "    n_items=20, max_users=2000\n",
    ")\n",
    "\n",
    "print(\"SASRec Results:\")\n",
    "for k, v in sasrec_results.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Two-Tower with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.retrieval.two_tower import TwoTowerRecommender\n",
    "\n",
    "# Train Two-Tower\n",
    "two_tower = TwoTowerRecommender(\n",
    "    embedding_dim=64,\n",
    "    hidden_dims=[128, 64],\n",
    "    dropout=0.2,\n",
    "    temperature=0.1,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=1024,\n",
    "    epochs=5,  # Reduce for demo\n",
    "    negative_samples=4,\n",
    "    use_faiss=True\n",
    ")\n",
    "\n",
    "two_tower.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Two-Tower\n",
    "two_tower_results = evaluator.evaluate(\n",
    "    two_tower, train, test,\n",
    "    n_items=20, max_users=2000\n",
    ")\n",
    "\n",
    "print(\"Two-Tower Results:\")\n",
    "for k, v in two_tower_results.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Similar items using Two-Tower embeddings\n",
    "sample_item = train['item_id'].value_counts().index[0]\n",
    "similar_items = two_tower.get_similar_items(sample_item, n_items=5)\n",
    "\n",
    "print(f\"Items similar to {sample_item}:\")\n",
    "for item_id, score in similar_items:\n",
    "    print(f\"  Item {item_id}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.explainable.explainer import RecommendationExplainer\n",
    "\n",
    "# Get item popularity for explainer\n",
    "item_popularity = train['item_id'].value_counts().to_dict()\n",
    "\n",
    "# Initialize explainer\n",
    "explainer = RecommendationExplainer(\n",
    "    user_feature_extractor=user_feature_extractor,\n",
    "    item_popularity=item_popularity\n",
    ")\n",
    "explainer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Generate explanations\n",
    "sample_user = train['visitor_id'].iloc[0]\n",
    "recs = sasrec.recommend(sample_user, n_items=5)\n",
    "\n",
    "print(f\"Recommendations for user {sample_user}:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "explanations = explainer.explain_batch(\n",
    "    user_id=sample_user,\n",
    "    recommendations=recs,\n",
    "    model_name='sasrec'\n",
    ")\n",
    "\n",
    "for exp in explanations:\n",
    "    print(f\"\\nItem {exp.item_id} (score: {exp.score:.4f})\")\n",
    "    print(f\"Summary: {exp.get_summary()}\")\n",
    "    print(f\"Confidence: {exp.confidence:.2f}\")\n",
    "    if len(exp.reasons) > 1:\n",
    "        print(\"All reasons:\")\n",
    "        print(exp.get_full_explanation())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Session + History Fusion Hybrid (Novelty #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.hybrid.funnel_aware import FunnelAwareHybridRecommender\n",
    "from src.models.baselines.popular import PopularItemsRecommender\n",
    "from src.models.collaborative.als import ALSRecommender\n",
    "from src.models.content.item2vec import Item2VecRecommender\n",
    "\n",
    "# Train component models\n",
    "popular = PopularItemsRecommender()\n",
    "popular.fit(train)\n",
    "\n",
    "als = ALSRecommender(factors=64, iterations=10)\n",
    "als.fit(train)\n",
    "\n",
    "item2vec = Item2VecRecommender(embedding_dim=64, window=5, epochs=5)\n",
    "item2vec.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hybrid with session model\n",
    "hybrid = FunnelAwareHybridRecommender(\n",
    "    popular_model=popular,\n",
    "    content_model=item2vec,\n",
    "    cf_model=als,\n",
    "    session_model=sasrec,  # Use SASRec for session component\n",
    "    score_normalization='minmax',\n",
    "    user_feature_extractor=user_feature_extractor\n",
    ")\n",
    "hybrid.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate hybrid\n",
    "hybrid_results = evaluator.evaluate(\n",
    "    hybrid, train, test,\n",
    "    n_items=20, max_users=2000\n",
    ")\n",
    "\n",
    "print(\"Session+History Fusion Hybrid Results:\")\n",
    "for k, v in hybrid_results.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all results\n",
    "all_results = [\n",
    "    gru4rec_results,\n",
    "    sasrec_results,\n",
    "    two_tower_results,\n",
    "    hybrid_results\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('ndcg@10', ascending=False)\n",
    "\n",
    "# Display results\n",
    "display_cols = ['model', 'precision@10', 'recall@10', 'ndcg@10', 'hit_rate', 'mrr']\n",
    "display_cols = [c for c in display_cols if c in results_df.columns]\n",
    "results_df[display_cols].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics = ['precision@10', 'recall@10', 'ndcg@10']\n",
    "models = results_df['model'].tolist()\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = results_df[metric].tolist()\n",
    "    ax.bar(x + i * width, values, width, label=metric)\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('V2.0 Model Comparison')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Item Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Get embeddings from Two-Tower\n",
    "item_embeddings = two_tower.get_item_embeddings()\n",
    "\n",
    "# Sample for visualization\n",
    "n_sample = min(5000, len(item_embeddings))\n",
    "sample_idx = np.random.choice(len(item_embeddings), n_sample, replace=False)\n",
    "sample_embeddings = item_embeddings[sample_idx]\n",
    "\n",
    "# Apply t-SNE\n",
    "print(\"Applying t-SNE...\")\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(sample_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot t-SNE\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    embeddings_2d[:, 0],\n",
    "    embeddings_2d[:, 1],\n",
    "    alpha=0.5,\n",
    "    s=5\n",
    ")\n",
    "\n",
    "ax.set_title('Item Embeddings (Two-Tower) - t-SNE Visualization')\n",
    "ax.set_xlabel('t-SNE 1')\n",
    "ax.set_ylabel('t-SNE 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Sequential models** (GRU4Rec, SASRec) capture temporal patterns in user behavior\n",
    "2. **Two-Tower** enables efficient retrieval with FAISS at scale\n",
    "3. **Session + History Fusion** combines short-term (session) and long-term (history) signals\n",
    "4. **Explainable AI** provides human-readable explanations with funnel awareness\n",
    "\n",
    "### Scientific Contributions\n",
    "\n",
    "- **Novelty #2**: Attention-based fusion of session and history signals\n",
    "- **Novelty #3**: Multi-strategy explainability (collaborative, content, intent, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df.to_csv('../data/processed/v2_notebook_results.csv', index=False)\n",
    "print(\"Results saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
